{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from micrograd.engine import Value\n",
    "from micrograd.nn import neuron, Layer\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[Value(data=1, grad=0), Value(data=0, grad=0)],\n",
       "  [Value(data=0, grad=0), Value(data=1, grad=0)],\n",
       "  [Value(data=1, grad=0), Value(data=1, grad=0)],\n",
       "  [Value(data=1, grad=0), Value(data=0, grad=0)],\n",
       "  [Value(data=1, grad=0), Value(data=1, grad=0)],\n",
       "  [Value(data=1, grad=0), Value(data=1, grad=0)],\n",
       "  [Value(data=1, grad=0), Value(data=1, grad=0)],\n",
       "  [Value(data=0, grad=0), Value(data=0, grad=0)],\n",
       "  [Value(data=0, grad=0), Value(data=1, grad=0)],\n",
       "  [Value(data=0, grad=0), Value(data=0, grad=0)],\n",
       "  [Value(data=0, grad=0), Value(data=0, grad=0)],\n",
       "  [Value(data=1, grad=0), Value(data=1, grad=0)],\n",
       "  [Value(data=0, grad=0), Value(data=1, grad=0)],\n",
       "  [Value(data=1, grad=0), Value(data=0, grad=0)],\n",
       "  [Value(data=1, grad=0), Value(data=1, grad=0)],\n",
       "  [Value(data=0, grad=0), Value(data=1, grad=0)],\n",
       "  [Value(data=1, grad=0), Value(data=0, grad=0)],\n",
       "  [Value(data=0, grad=0), Value(data=0, grad=0)],\n",
       "  [Value(data=1, grad=0), Value(data=0, grad=0)],\n",
       "  [Value(data=0, grad=0), Value(data=1, grad=0)]],\n",
       " [Value(data=1, grad=0),\n",
       "  Value(data=1, grad=0),\n",
       "  Value(data=0, grad=0),\n",
       "  Value(data=1, grad=0),\n",
       "  Value(data=0, grad=0),\n",
       "  Value(data=0, grad=0),\n",
       "  Value(data=0, grad=0),\n",
       "  Value(data=0, grad=0),\n",
       "  Value(data=1, grad=0),\n",
       "  Value(data=0, grad=0),\n",
       "  Value(data=0, grad=0),\n",
       "  Value(data=0, grad=0),\n",
       "  Value(data=1, grad=0),\n",
       "  Value(data=1, grad=0),\n",
       "  Value(data=0, grad=0),\n",
       "  Value(data=1, grad=0),\n",
       "  Value(data=1, grad=0),\n",
       "  Value(data=0, grad=0),\n",
       "  Value(data=1, grad=0),\n",
       "  Value(data=1, grad=0)])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = [random.choice([0,1]) for _ in range(20)]\n",
    "X2 = [random.choice([0,1]) for _ in range(20)]\n",
    "X = [[Value(x1),Value(x2)] for x1,x2 in zip(X1,X2)]\n",
    "y =[Value((x1!=x2)*1) for x1,x2 in zip(X1,X2)]\n",
    "X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp:\n",
    "    def __init__(self):\n",
    "        self.layers = [Layer(2,8), neuron(8, nonlin=False)]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"MLP of [{', '.join(str(layer) for layer in self.layers)}]\"\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.parameters():\n",
    "            p.grad = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss: 2.9347573749796617e-05\n",
      "epoch 1 loss: 2.6956314867070216e-05\n",
      "epoch 2 loss: 2.5152705171226038e-05\n",
      "epoch 3 loss: 2.3261274922975454e-05\n",
      "epoch 4 loss: 2.140250030624365e-05\n",
      "epoch 5 loss: 2.0083606461013604e-05\n",
      "epoch 6 loss: 1.854829687928174e-05\n",
      "epoch 7 loss: 1.7138804116925817e-05\n",
      "epoch 8 loss: 1.6095558075231654e-05\n",
      "epoch 9 loss: 1.4834769458169924e-05\n",
      "epoch 10 loss: 1.3835468144887575e-05\n",
      "epoch 11 loss: 1.2941682374566239e-05\n",
      "epoch 12 loss: 1.1952807306831718e-05\n",
      "epoch 13 loss: 1.120183659726725e-05\n",
      "epoch 14 loss: 1.0467064192956111e-05\n",
      "epoch 15 loss: 9.680989031161288e-06\n",
      "epoch 16 loss: 9.106790265416419e-06\n",
      "epoch 17 loss: 8.506126111342424e-06\n",
      "epoch 18 loss: 7.87675264275187e-06\n",
      "epoch 19 loss: 7.4335248563752166e-06\n",
      "epoch 20 loss: 6.941873026781015e-06\n",
      "epoch 21 loss: 6.4350779571782615e-06\n",
      "epoch 22 loss: 6.090219255228598e-06\n",
      "epoch 23 loss: 5.686843672746244e-06\n",
      "epoch 24 loss: 5.276680652667961e-06\n",
      "epoch 25 loss: 5.006275863933529e-06\n",
      "epoch 26 loss: 4.674587508024656e-06\n",
      "epoch 27 loss: 4.3411047073712385e-06\n",
      "epoch 28 loss: 4.127408611754652e-06\n",
      "epoch 29 loss: 3.8541773733303186e-06\n",
      "epoch 30 loss: 3.5819108762981916e-06\n",
      "epoch 31 loss: 3.4116683228511787e-06\n",
      "epoch 32 loss: 3.186303302060808e-06\n",
      "epoch 33 loss: 2.9631829109870796e-06\n",
      "epoch 34 loss: 2.8264410000119697e-06\n",
      "epoch 35 loss: 2.6404160593705346e-06\n",
      "epoch 36 loss: 2.4569573645750882e-06\n",
      "epoch 37 loss: 2.346207438128148e-06\n",
      "epoch 38 loss: 2.1926170977502243e-06\n",
      "epoch 39 loss: 2.0413197113548597e-06\n",
      "epoch 40 loss: 1.950870941285081e-06\n",
      "epoch 41 loss: 1.824089735616293e-06\n",
      "epoch 42 loss: 1.6989859880919242e-06\n",
      "epoch 43 loss: 1.6245049663964962e-06\n",
      "epoch 44 loss: 1.5199259394450978e-06\n",
      "epoch 45 loss: 1.4162402190452254e-06\n",
      "epoch 46 loss: 1.3544109118916364e-06\n",
      "epoch 47 loss: 1.268243835141808e-06\n",
      "epoch 48 loss: 1.1821337830750458e-06\n",
      "epoch 49 loss: 1.1304054133852933e-06\n"
     ]
    }
   ],
   "source": [
    "for _ in range(50):\n",
    "    #one epoch of training\n",
    "    clf.zero_grad()\n",
    "    loss = Value(0)\n",
    "    for i in range(len(X)):\n",
    "        out = clf(X[i])\n",
    "        loss = loss + (-y[i] + out)*(-y[i] + out)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    #update paramters\n",
    "\n",
    "    for p in clf.parameters():\n",
    "        p.data += -0.01*p.grad\n",
    "\n",
    "    print(f'epoch {_} loss: {loss.data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(data=0.999849315121685, grad=0)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf([1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
